{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import psycopg2\n",
    "from sql_queries_script import *\n",
    "\n",
    "\n",
    "def to_process_killers_data(cur,filepath):\n",
    "    df = pd.read_csv(filepath, index_col=None, header=0)\n",
    "    for value in df.values:\n",
    "        KillerID,AgeFirstKill,AgeLastKill,YearBorn,Motive,Sex,Race,Sentence,InsanityPlea=value\n",
    "\n",
    "        #insert killers bio records\n",
    "        killers_data=(KillerID,YearBorn,Race,Sex)\n",
    "        cur.execute(killers_bio_table_insert,killers_data)\n",
    "\n",
    "        #insert killers additional details records\n",
    "        killers_data_add=(KillerID,AgeFirstKill,AgeLastKill,Motive,Sentence,InsanityPlea)\n",
    "        cur.execute(killers_additional_table_insert,killers_data_add)\n",
    "\n",
    "    print(f\"Records inserted for file {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  load_data(cur,conn,filepath,func):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root,'*.csv'))\n",
    "        for f in files:\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    num_files = len(all_files)\n",
    "    print('{} files found in {}'.format(num_files, filepath))\n",
    "    \n",
    "    for i, datafile in enumerate(all_files, 1):\n",
    "            func(cur, datafile)\n",
    "            conn.commit()\n",
    "            print('{}/{} files processed.'.format(i, num_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Driver function for loading killers bio and killers details into Postgres database\n",
    "    \"\"\"\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=mysparkdb user=postgres password=1234\")\n",
    "    cur = conn.cursor()\n",
    "    load_data(cur, conn, filepath=r'C:\\Users\\PG\\Documents\\data engineer\\projects-portfolio\\postgresql', func=to_process_killers_data)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 files found in C:\\Users\\PG\\Documents\\data engineer\\projects-portfolio\\postgresql\n",
      "Records inserted for file C:\\Users\\PG\\Documents\\data engineer\\projects-portfolio\\postgresql\\killers_and_motives1.csv\n",
      "1/2 files processed.\n",
      "Records inserted for file C:\\Users\\PG\\Documents\\data engineer\\projects-portfolio\\postgresql\\killers_and_motives2.csv\n",
      "2/2 files processed.\n",
      "\n",
      "\n",
      "Finished processing!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"\\n\\nFinished processing!!!\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
